{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDuPjpKigw3w"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON dictionary\n",
        "with open('video_dictionary.json', 'r') as file:\n",
        "    sign_language_dict = json.load(file)\n",
        "\n",
        "# Lowercase all keys in the dictionary\n",
        "sign_language_dict = {key.lower(): value for key, value in sign_language_dict.items()}\n",
        "\n",
        "# Define your new dictionary (my_dict)\n",
        "my_dict = {\n",
        "    \"a\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-A.jpg\",\n",
        "    \"b\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-B.jpg\",\n",
        "    \"c\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-C.jpg\",\n",
        "    \"d\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-D.jpg\",\n",
        "    \"e\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-E.jpg\",\n",
        "    \"f\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-F.jpg\",\n",
        "    \"g\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-G.jpg\",\n",
        "    \"h\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-H.jpg\",\n",
        "    \"i\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-I.jpg\",\n",
        "    \"j\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-J.jpg\",\n",
        "    \"k\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-K.jpg\",\n",
        "    \"l\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-L.jpg\",\n",
        "    \"m\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-M.jpg\",\n",
        "    \"n\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-N.jpg\",\n",
        "    \"o\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-O.jpg\",\n",
        "    \"p\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-P.jpg\",\n",
        "    \"q\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-Q.jpg\",\n",
        "    \"r\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-R.jpg\",\n",
        "    \"s\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-S.jpg\",\n",
        "    \"t\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-T.jpg\",\n",
        "    \"u\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-U.jpg\",\n",
        "    \"v\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-V.jpg\",\n",
        "    \"w\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-W.jpg\",\n",
        "    \"x\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-X.jpg\",\n",
        "    \"y\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-Y.jpg\",\n",
        "    \"z\": \"http://indiandeaf.org/Images/ISL/isl-Alphabet-Z.jpg\",\n",
        "}\n",
        "sign_language_dict.update(my_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load NLTK stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def normalize_and_tokenize(text):\n",
        "    # Remove anything within brackets and normalize\n",
        "    text = re.sub(r'\\[.*?\\]|\\(.*?\\)|\\{.*?\\}', '', text)\n",
        "    text = text.lower()  # Lowercase the text\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    tokens = [token for token in tokens if token not in STOPWORDS]\n",
        "    return tokens\n",
        "\n",
        "# Example input sentence\n",
        "input_text = \"Hello, world! This is an example sentence, Nadam.\"\n",
        "tokens = normalize_and_tokenize(input_text)\n",
        "print(tokens)  # Output: ['hello', 'world', 'example', 'sentence']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsmUE0MWhDz1",
        "outputId": "0dd9a822-e1cc-454f-b0e7-76b9c9af0a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'world', 'example', 'sentence', 'nadam']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_synonym(word):\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name() in sign_language_dict:\n",
        "                return lemma.name()\n",
        "    return word\n",
        "\n",
        "# Apply synonym mapping to tokens\n",
        "tokens = [get_synonym(token) for token in tokens]\n",
        "print(tokens)  # Tokens mapped to your dictionary's keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TJgXoIghOiG",
        "outputId": "10dd3121-b272-4607-bcbc-516e8bb41635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'universe', 'example', 'sentence', 'nadam']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_links = []  # Initialize video links outside the loop\n",
        "\n",
        "for token in tokens:  # Loop through each token\n",
        "    if token in sign_language_dict:\n",
        "        video_links.append(sign_language_dict[token])  # Append link if token exists in dictionary\n",
        "    else:\n",
        "        # Break the unknown word into individual letters\n",
        "        for letter in token:\n",
        "            if letter in sign_language_dict:\n",
        "                video_links.append(sign_language_dict[letter])  # Append letter links\n",
        "            else:\n",
        "                video_links.append(\"link_to_default_unknown_video\")  # Handle unknown letters\n",
        "\n",
        "print(video_links)  # List of video links corresponding to the input sentence\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW42RptgFKgw",
        "outputId": "289ebf70-7fe6-45a8-bfbd-5fb55123a610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://drive.google.com/uc?id=1q25_z8OFiFiWlSAKuESn4mw9Cytpxmr3&export=download', 'https://drive.google.com/uc?id=1VeUV_YBwkq_avehydlDTXqAKHDpYthyT&export=download', 'https://drive.google.com/uc?id=1lmFGQmLvm1NqCAzfQ3GSGeBVZPMqc-ud&export=download', 'https://drive.google.com/uc?id=1vL85TnmLZ8svKA6CiRFCwtMCzy_G-G_B&export=download', 'http://indiandeaf.org/Images/ISL/isl-Alphabet-N.jpg', 'http://indiandeaf.org/Images/ISL/isl-Alphabet-A.jpg', 'http://indiandeaf.org/Images/ISL/isl-Alphabet-D.jpg', 'http://indiandeaf.org/Images/ISL/isl-Alphabet-A.jpg', 'http://indiandeaf.org/Images/ISL/isl-Alphabet-M.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input_text(input_text):\n",
        "    tokens = normalize_and_tokenize(input_text)\n",
        "    tokens = [get_synonym(token) for token in tokens]\n",
        "\n",
        "    video_links = []\n",
        "    for token in tokens:\n",
        "        if token in sign_language_dict:\n",
        "            video_links.append(sign_language_dict[token])\n",
        "        else:\n",
        "            video_links.append(\"link_to_default_unknown_video\")  # Handle unmatched words\n",
        "\n",
        "    return video_links\n",
        "\n",
        "# Example: Process an input text\n",
        "input_text = \"Hello world! This is an example sentence.\"\n",
        "video_links = process_input_text(input_text)\n",
        "print(video_links)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y75yxw8MhrR3",
        "outputId": "3a07ddd1-379e-400b-d567-add13989dfa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://drive.google.com/uc?id=1q25_z8OFiFiWlSAKuESn4mw9Cytpxmr3&export=download', 'https://drive.google.com/uc?id=1VeUV_YBwkq_avehydlDTXqAKHDpYthyT&export=download', 'https://drive.google.com/uc?id=1lmFGQmLvm1NqCAzfQ3GSGeBVZPMqc-ud&export=download', 'https://drive.google.com/uc?id=1vL85TnmLZ8svKA6CiRFCwtMCzy_G-G_B&export=download']\n"
          ]
        }
      ]
    }
  ]
}